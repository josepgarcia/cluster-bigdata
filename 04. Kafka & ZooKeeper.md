> [!NOTE] En construcción
# Resumen instalación

^aee8de

![[kafka_zookeeper.png]]
# Requisitos
[[#^aee8de]]
SSH sin contraseña

# Configuración server
En el server

cd /opt
wget https://downloads.apache.org/kafka/3.7.0/kafka-3.7.0-src.tgz
descomprimir
ln -s kafka-3..... kafka
chown -R hadoop:hadoop kafka kafka-3.7...


Dentro de kafka/config, archivo zookeeper.properties
podemos modificar la carpeta de zookeeper

the directory where the snapshot is stored.
dataDir=/tmp/zookeeper

---
# Configuración clientes
***** Probar descargar los binarios para no tener que ejecutar gradelew **********
https://downloads.apache.org/kafka/3.7.0/kafka_2.12-3.7.0.tgz

**Arrancamos zookeeper**
cd /opt/kafka
./gradlew jar -PscalaVersion=2.13.12

En:
/opt/kafka/bin

./zookeeper-server-start.sh ../config/zookeeper.properties

----
En los workers
cd /opt
wget https://downloads.apache.org/kafka/3.7.0/kafka_2.12-3.7.0.tgz
descomprimr, enlace

dentro de config
vi server.properties

```
# Entero que identifica el nodo, debe ser distinto en cada nodo  
broker.id=1  
  
# Carpeta donde se guardan los logs, lo mismo que en Zookeeper  
log.dirs=/kafka-logs  
  
# Host y puerto donde está escuchando ZooKeeper  
zookeeper.connect=172.17.0.4:2181    
  
# Host y puerto donde está escuchando esta instancia de Apache, normalmente no hace falta especificar  
listeners=PLAINTEXT://<hostip>:9092
```

root@nuc1:/opt/kafka/bin# ./kafka-server-start.sh ../config/server.properties &


https://www.albertcoronado.com/2020/09/09/instalacion-de-un-cluster-de-apache-kafka-paso-a-paso/

# Trabajar con el cluster

Ya tenemos nuestro cluster funcionando y ya podemos empezar a crear tópics, publicar y consumir mensajes. Podemos conectarnos a cualquier nodo de Apache Kafka que todos deberian deveolver siempre la misma información(Para eso es un cluster):

```
# Crear un topic con una replica(replication factor 2) y dos particiones  
./kafka-topics.sh --create --bootstrap-server 172.17.0.5:9092 --replication-factor 2 --partitions 2 --topic test-cluster  
  
# Leer la lista de topics(Para comprobar que se ha creado correctamente)  
kafka-topics.sh --list --bootstrap-server 172.17.0.6:9092  
  
# Nos abrimos una consola como productor de mensajes  
kafka-console-producer.sh --broker-list 172.17.0.5:9092 --topic test-cluster  
  
# Nos abrimos una consola como consumidor de mensajes  
kafka-console-consumer.sh --bootstrap-server 172.17.0.6:9092 --topic test-cluster –from-beginning
```

---
## Code
Ejemplo de uso con python.

```
'''producer.py'''
from kafka import KafkaProducer
import time

# Configuración del servidor Kafka y el tema al que enviaremos mensajes
bootstrap_servers = ['nuc1:9092']
topic_name = 'test1'

# Crear un productor de Kafka
producer = KafkaProducer(bootstrap_servers=bootstrap_servers)

# Enviar mensajes al tema
for i in range(1, 6):
        mensaje = f"Mensaje {i}"
        producer.send(topic_name, mensaje.encode('utf-8'))
        print(f"Mensaje enviado: {mensaje}")
        time.sleep(1)  # Esperar 1 segundo entre cada mensaje

producer.close()

```

```
'''consumer.py'''
from kafka import KafkaConsumer

# Configuración del servidor Kafka y el tema al que nos conectaremos
bootstrap_servers = ['nuc1:9092']
topic_name = 'test1'

# Crear un consumidor de Kafka
consumer = KafkaConsumer(
        topic_name,
        group_id='grupo1',
        bootstrap_servers=bootstrap_servers,
        auto_offset_reset='earliest')

# Leer mensajes del tema
for mensaje in consumer:
    print(f"Mensaje recibido: {mensaje.value.decode('utf-8')}")

```
# +INFO
https://www.albertcoronado.com/2020/09/09/instalacion-de-un-cluster-de-apache-kafka-paso-a-paso/
